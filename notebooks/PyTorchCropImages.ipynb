{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Dataset: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "NOTE:\n",
    "1. The validation range is changed to small size for debug.\n",
    "2. Mean:  [0.90960454 0.81946206 0.87811487]\n",
    "   Std:  [0.13244118 0.24944844 0.16392948]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # stateless functions\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prostate-cancer-grade-assessment.zip  test.csv\t train_images\n",
      "sample_submission.csv\t\t      train.csv  train_label_masks\n",
      "isup_grade\n",
      "2       1\n",
      "3    1242\n",
      "dtype: int64\n",
      "Int64Index([7273], dtype='int64')\n",
      "Collected small samples 97\n"
     ]
    }
   ],
   "source": [
    "BASE_FOLDER = \"/project/data/\"\n",
    "!ls {BASE_FOLDER}\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(BASE_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(BASE_FOLDER, 'test.csv'))\n",
    "\n",
    "image_dir = os.path.join(BASE_FOLDER, \n",
    "                         'train_images')\n",
    "mask_dir = os.path.join(BASE_FOLDER,\n",
    "                       'train_label_masks')\n",
    "\n",
    "print(train[train['gleason_score']=='4+3'].groupby(['isup_grade']).size())\n",
    "\n",
    "query = (train['gleason_score'] == \"4+3\") & (train['isup_grade'] ==2)\n",
    "print(train.index[query])\n",
    "\n",
    "train.drop(train.index[query], inplace=True)\n",
    "\n",
    "train[\"gleason_score\"] = train[\"gleason_score\"].apply(lambda x : \"0+0\" if x==\"negative\" else x)\n",
    "\n",
    "g0_r = train[(train['gleason_score']==\"0+0\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g0_k = train[(train['gleason_score']==\"0+0\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "\n",
    "g1_r = train[(train['gleason_score']==\"3+3\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g1_k = train[(train['gleason_score']==\"3+3\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "\n",
    "g2_r = train[(train['gleason_score']==\"3+4\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g2_k = train[(train['gleason_score']==\"3+4\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "\n",
    "g3_r = train[(train['gleason_score']==\"4+3\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g3_k = train[(train['gleason_score']==\"4+3\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "\n",
    "# 15 for radboud isup 4 : 4+4, 3+5 , 5+3\n",
    "g4_44_r = train[(train['gleason_score']==\"4+4\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g4_35_r = train[(train['gleason_score']==\"3+5\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g4_53_r = train[(train['gleason_score']==\"5+3\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "\n",
    "# 15 for karolinska isup 4 : 4+4, 3+5 , 5+3\n",
    "g4_44_k = train[(train['gleason_score']==\"4+4\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "g4_35_k = train[(train['gleason_score']==\"3+5\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "g4_53_k = train[(train['gleason_score']==\"5+3\") & (train['data_provider'] == 'karolinska')].sample(2).index # we have we few samples here\n",
    "\n",
    "# 15 for radboud isup 5 : 4+5, 5+4 , 5+5\n",
    "g5_45_r = train[(train['gleason_score']==\"4+5\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g5_54_r = train[(train['gleason_score']==\"5+4\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "g5_55_r = train[(train['gleason_score']==\"5+5\") & (train['data_provider'] == 'radboud')].sample(5).index\n",
    "\n",
    "# 15 for karolinska isup 5 : 4+5, 5+4 , 5+5\n",
    "g5_45_k = train[(train['gleason_score']==\"4+5\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "g5_54_k = train[(train['gleason_score']==\"5+4\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "g5_55_k = train[(train['gleason_score']==\"5+5\") & (train['data_provider'] == 'karolinska')].sample(5).index\n",
    "\n",
    "indices_samples = g0_r | g0_k |  g1_r | g1_k | g2_r | g2_k | g3_r | g3_k | g4_44_r | g4_35_r | g4_53_r | g4_44_k | g4_35_k | g4_53_k | g5_45_r | g5_54_r | g5_55_r | g5_45_k  | g5_54_k | g5_55_k\n",
    "\n",
    "print(\"Collected small samples\" , len(indices_samples))\n",
    "\n",
    "small_train = train.loc[indices_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10616\n",
      "/project/data/train_images/1e1862f8927813cacf7391cc55848ba4.tiff\n"
     ]
    }
   ],
   "source": [
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "\n",
    "listdir(image_dir)\n",
    "ids = [splitext(file)[0] for file in listdir(image_dir)\n",
    "                    if  file.endswith('.tiff')]\n",
    "print(len(ids))\n",
    "\n",
    "\n",
    "image = skimage.io.MultiImage(os.path.join(image_dir,ids[0]+\".tiff\"))\n",
    "image = np.array(os.path.join(image_dir,ids[0]+\".tiff\"))\n",
    "print(os.path.join(image_dir,ids[0]+\".tiff\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, masks_dir, scale=1):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.scale = scale\n",
    "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
    "\n",
    "        self.ids = [splitext(file)[0] for file in listdir(imgs_dir)\n",
    "                    if not file.endswith('.tiff')]\n",
    "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, pil_img, scale):\n",
    "        w, h = pil_img.size\n",
    "        newW, newH = int(scale * w), int(scale * h)\n",
    "        assert newW > 0 and newH > 0, 'Scale is too small'\n",
    "        pil_img = pil_img.resize((newW, newH))\n",
    "\n",
    "        img_nd = np.array(pil_img)\n",
    "\n",
    "        if len(img_nd.shape) == 2:\n",
    "            img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "        # HWC to CHW\n",
    "        img_trans = img_nd.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "\n",
    "        return img_trans\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        image = skimage.io.MultiImage(os.path.join())[-2]\n",
    "        image = np.array(image)\n",
    "\n",
    "        mask = skimage.io.MultiImage(slide_path)[-2]\n",
    "        mask = np.array(image)\n",
    "\n",
    "        idx = self.ids[i]\n",
    "        mask_file = glob(self.masks_dir + idx + '*')\n",
    "        img_file = glob(self.imgs_dir + idx + '*')\n",
    "        assert len(mask_file) == 1, \\\n",
    "            f'Either no mask or multiple masks found for the ID {idx}: {mask_file}'\n",
    "        assert len(img_file) == 1, \\\n",
    "            f'Either no image or multiple images found for the ID {idx}: {img_file}'\n",
    "        mask = Image.open(mask_file[0])\n",
    "        img = Image.open(img_file[0])\n",
    "\n",
    "        assert img.size == mask.size, \\\n",
    "            f'Image and mask {idx} should be the same size, but are {img.size} and {mask.size}'\n",
    "\n",
    "        img = self.preprocess(img, self.scale)\n",
    "        mask = self.preprocess(mask, self.scale)\n",
    "\n",
    "        return {'image': torch.from_numpy(img), 'mask': torch.from_numpy(mask)}\n",
    "    \n",
    "# Customized Dataset\n",
    "class ProstateCancerDataset(Dataset):\n",
    "    \"\"\"Prostate Cancer Biopsy Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file\n",
    "            root_dir (string): Path to the directory with all images\n",
    "            transform (callable, optional): Optional transform to be applied on an image sample\n",
    "        \"\"\"\n",
    "        # Shuffle dataframes with fixed seed; otherwise, validation set only get cancerous samples\n",
    "        self.cancer_df = pd.read_csv(csv_file).sample(frac=1, random_state=1)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cancer_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, f'{self.cancer_df.iloc[idx, 0]}_0.png')\n",
    "        # (D,W,H)\n",
    "        img = io.imread(img_path)\n",
    "        image = tile_patriot(img, sz=128, N=16) # added new \n",
    "        img = cv2.hconcat([cv2.vconcat([image[0], image[1], image[2], image[3]]), \n",
    "                             cv2.vconcat([image[4], image[5], image[6], image[7]]), \n",
    "                             cv2.vconcat([image[8], image[9], image[10], image[11]]), \n",
    "                             cv2.vconcat([image[12], image[13], image[14], image[15]])])\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        isup = self.cancer_df.iloc[idx, 2]\n",
    "        gleason = self.cancer_df.iloc[idx, 3]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        sample = {'image': img, 'isup_grade': isup, 'gleason_score': gleason}\n",
    "        return sample          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "image_cropped_dir = '/project/yi_data/train_crop_128'\n",
    "NUM_TRAIN = 6800 #8492\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32   # use float throughout the training\n",
    "print_every = 100\n",
    "\n",
    "SCALE_SZ = 128\n",
    "BATCH_SZ = 8\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-176cf5476c2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchnet'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import plot_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_patriot(img, sz=128, N=16):\n",
    "    shape = img.shape\n",
    "    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n",
    "    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n",
    "                 constant_values=255)\n",
    "    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n",
    "    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n",
    "    if len(img) < N:\n",
    "        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n",
    "    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n",
    "    img = img[idxs]\n",
    "    return img#[N,size,size,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized Dataset\n",
    "class ProstateCancerDataset(Dataset):\n",
    "    \"\"\"Prostate Cancer Biopsy Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file\n",
    "            root_dir (string): Path to the directory with all images\n",
    "            transform (callable, optional): Optional transform to be applied on an image sample\n",
    "        \"\"\"\n",
    "        # Shuffle dataframes with fixed seed; otherwise, validation set only get cancerous samples\n",
    "        self.cancer_df = pd.read_csv(csv_file).sample(frac=1, random_state=1)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cancer_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, f'{self.cancer_df.iloc[idx, 0]}_0.png')\n",
    "        # (D,W,H)\n",
    "        img = io.imread(img_path)\n",
    "        image = tile_patriot(img, sz=128, N=16) # added new \n",
    "        img = cv2.hconcat([cv2.vconcat([image[0], image[1], image[2], image[3]]), \n",
    "                             cv2.vconcat([image[4], image[5], image[6], image[7]]), \n",
    "                             cv2.vconcat([image[8], image[9], image[10], image[11]]), \n",
    "                             cv2.vconcat([image[12], image[13], image[14], image[15]])])\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        isup = self.cancer_df.iloc[idx, 2]\n",
    "        gleason = self.cancer_df.iloc[idx, 3]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        sample = {'image': img, 'isup_grade': isup, 'gleason_score': gleason}\n",
    "        return sample        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Customize Transforms\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image sample to the given size\n",
    "    Args:\n",
    "        output_size (tuple): Desired output size. Output is matched to output_size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, tuple)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        img = transform.resize(sample['image'], self.output_size)\n",
    "        return {'image': img, 'isup_grade': sample['isup_grade'], 'gleason_score': sample['gleason_score']}\n",
    "    \n",
    "\"\"\"\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        img = sample['image']        \n",
    "        # Swap color axis to [C,H,W]\n",
    "        img = img.transpose(2,0,1)\n",
    "        return {'image': img, 'isup_grade': sample['isup_grade'], 'gleason_score': sample['gleason_score']}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compse tranforms of totensor\n",
    "# More transformer to try: crop, normalize, etc.\n",
    "# And transformer is a useful tool for data augmentation\n",
    "biopsy_train = ProstateCancerDataset(csv_file='train_512.csv',\n",
    "                                     root_dir=image_cropped_dir,\n",
    "                                     transform=T.Compose([\n",
    "                                                 T.ToTensor(),\n",
    "                                                 T.Normalize((0.90960454,0.81946206,0.87811487),\n",
    "                                                             (0.13244118,0.24944844,0.16392948)),\n",
    "                                     ]))\n",
    "\n",
    "loader_train = DataLoader(biopsy_train, batch_size=BATCH_SZ, num_workers=4,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = DataLoader(biopsy_train, batch_size=BATCH_SZ, num_workers=4,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 8492)))  #NUM_TRAIN+200  Use smaller size for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(biopsy_train\n",
    "                    ):\n",
    "    print(i)\n",
    "    print(k['image'].shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isup_distr = defaultdict(int)\n",
    "for batch_i, batch_sample in enumerate(loader_train):\n",
    "    #for grade in batch_sample['isup_grade']:\n",
    "        #print(int(grade))\n",
    "    #    isup_distr[int(grade)] += 1\n",
    "    #print(batch_sample['image'][0].shape)\n",
    "    #for s_i, sample in enumerate(batch_sample['isup_grade']):\n",
    "    #    print(sample)\n",
    "    #print(batch_sample['isup_grade'])\n",
    "    #print(batch_sample['image'][0])\n",
    "    print(batch_sample['image_id'][0])\n",
    "    plt.imshow(batch_sample['image'][0].permute(1,2,0))\n",
    "    assert False\n",
    "print(isup_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    loss_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-'*10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()   # Set model to training phase\n",
    "            else:\n",
    "                model.eval()    # Set model to evaluate phase\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for batch in dataloaders[phase]:\n",
    "                inputs = batch['image'].to(device=device, dtype=dtype)\n",
    "                labels = batch['isup_grade'].to(device=device, dtype=torch.long)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward, track history if only in training\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #print(loss.item())\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "            \n",
    "            # End of epoch\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            print('{} Loss: {:4f} Acc: {:4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            else:\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                loss_history.append(epoch_loss)\n",
    "                \n",
    "            if scheduler is not None and phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:0f}s'.format(time_elapsed//60, time_elapsed%60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, train_acc_history, val_acc_history\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "\n",
    "def initialize_model(num_classes, feature_extract=False, use_pretrained=False):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    #input_size = 128\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Layer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "    \n",
    "hidden_layer_size = 100\n",
    "learning_rate = 4e-4\n",
    "\n",
    "model_fc = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3*SCALE_SZ*SCALE_SZ, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 6)\n",
    ")\n",
    "\n",
    "# Send the model to GPU/CPU\n",
    "model_fc = model_fc.to(device)\n",
    "\n",
    "# Use Nesterov momentum\n",
    "optimizer = optim.SGD(model_fc.parameters(),\n",
    "                      lr=learning_rate,\n",
    "                      momentum=.9,\n",
    "                      nesterov=True)\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=learning_rate)\n",
    "\"\"\"\n",
    "# Learning Rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "best_model, loss_history, train_acc_history, val_acc_history = train_model(model_fc, {'train': loader_train, 'val': loader_val}, F.cross_entropy, optimizer, None, 30)\n",
    "\n",
    "#train_sequential(model, optimizer, scheduler, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "    \n",
    "hidden_layer_size = 100\n",
    "learning_rate = 4e-4\n",
    "\n",
    "model_fc = nn.Sequential(\n",
    "    Flatten(),\n",
    "#     nn.Linear(3*SCALE_SZ*SCALE_SZ, hidden_layer_size),\n",
    "    nn.Linear(3*512*512, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 6)\n",
    ")\n",
    "\n",
    "# Send the model to GPU/CPU\n",
    "model_fc = model_fc.to(device)\n",
    "\n",
    "# Use Nesterov momentum\n",
    "optimizer = optim.SGD(model_fc.parameters(),\n",
    "                      lr=learning_rate,\n",
    "                      momentum=.9,\n",
    "                      nesterov=True)\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=learning_rate)\n",
    "\"\"\"\n",
    "# Learning Rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "best_model, loss_history, train_acc_history, val_acc_history = train_model(model_fc, {'train': loader_train, 'val': loader_val}, F.cross_entropy, optimizer, None, 30)\n",
    "\n",
    "#train_sequential(model, optimizer, scheduler, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(loss_history, 'o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(train_acc_history, '-o')\n",
    "plt.plot(val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "Reference: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_ft, input_size = initialize_model(6)\n",
    "#print(model_ft)\n",
    "# Send the model to GPU/CPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model_ft.parameters(),\n",
    "                      lr=3e-3,\n",
    "                      momentum=.9,\n",
    "                      nesterov=True)\n",
    "\n",
    "best_model, loss_history, train_acc_history, val_acc_history = train_model(model_ft, {'train': loader_train, 'val': loader_val}, F.cross_entropy, optimizer, None, 30)\n",
    "print(loss_history)\n",
    "print(train_acc_history)\n",
    "print(val_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "Graphs\n",
    "1. loss vs. iterations\n",
    "2. Train/Validation accuracy along epoch\n",
    "\"\"\"\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(loss_history, 'o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(train_acc_history, '-o')\n",
    "plt.plot(val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "CodeCell": {
   "cm_config": {
    "lineWrapping": true
   }
  },
  "MarkdownCell": {
   "cm_config": {
    "lineWrapping": true
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
