{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# assert '.'.join(torch.__version__.split('.')[:2]) == '1.4'\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUNet_trial(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.downsample1 = nn.Conv2d(3, 64, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample2 = nn.Conv2d(64, 128, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample3 = nn.Conv2d(128, 256, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample4 = nn.Conv2d(256, 512, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample5 = nn.Conv2d(512, 1024, 3, stride=1, padding=1,bias=True)\n",
    "        \n",
    "        self.int_conv_w1 = nn.Conv2d(1024,512,3,padding=1,bias=True)\n",
    "        self.int_conv_w1 = nn.Conv2d(512,256,3,padding=1,bias=True)\n",
    "        self.int_conv_w1 = nn.Conv2d(256,128,3,padding=1,bias=True)\n",
    "        self.int_conv_w1 = nn.Conv2d(128,64,3,padding=1,bias=True)\n",
    "\n",
    "        self.upsample1 = nn.ConvTranspose2d(1024, 512, 3, stride=1, padding=1, bias=True)\n",
    "        self.upsample2 = nn.ConvTranspose2d(512, 256, 3, stride=1, padding=1, bias=True)\n",
    "        self.upsample3 = nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1, bias=True)        \n",
    "        self.upsample4 = nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1, bias=True)\n",
    "        \n",
    "        self.conv_w1 = nn.Conv2d(in_channels=in_channel,out_channels=64,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w1.weight)\n",
    "        \n",
    "        self.conv_w2 = nn.Conv2d(in_channels=64 ,out_channels=128,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w2.weight)\n",
    "\n",
    "        self.conv_w3 = nn.Conv2d(in_channels=128 ,out_channels=256,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w3.weight)\n",
    "\n",
    "        self.conv_w4 = nn.Conv2d(in_channels=256 ,out_channels=512,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w4.weight)\n",
    "\n",
    "        self.conv_w5 = nn.Conv2d(in_channels=512 ,out_channels=1024,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w5.weight)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.deconv_w1 = nn.ConvTranspose2d(1024,512,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w1.weight)\n",
    "        \n",
    "        self.rconv_w1 = nn.Conv2d(1024 ,512,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w1.weight)\n",
    "        \n",
    "        self.deconv_w2 = nn.ConvTranspose2d(512,256,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w2.weight)\n",
    "\n",
    "        self.rconv_w2 = nn.Conv2d(512 ,256,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w2.weight)\n",
    "        \n",
    "        self.deconv_w3 = nn.ConvTranspose2d(256,128,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w3.weight)\n",
    "        \n",
    "        self.rconv_w3 = nn.Conv2d(256 ,128,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w3.weight)\n",
    "        \n",
    "        self.deconv_w4 = nn.ConvTranspose2d(128,64,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w4.weight)\n",
    "        \n",
    "        self.rconv_w4 = nn.Conv2d(128 , 64,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w4.weight)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, num_classes, 1)\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****       \n",
    "        \n",
    "        \n",
    "        conv_out_1 = F.relu(self.downsample1(x))\n",
    "        print(\"Input shape : {}, Conv. 1 output shape : {} \".format(x.shape,conv_out_1.shape))\n",
    "\n",
    "        max_pool_1 = F.max_pool2d(conv_out_1, 2)\n",
    "        print(\"Max. pool 1 output shape : {}\".format(max_pool_1.shape)) # [5, 64, 112, 112]\n",
    "\n",
    "        conv_out_2 = F.relu(self.downsample2(max_pool_1))\n",
    "        print(\"Conv. 2 output shape : {}\".format(conv_out_2.shape))\n",
    "\n",
    "        max_pool_2 = F.max_pool2d(conv_out_2, 2)\n",
    "        print(\"Max pool 2 output shape : {}\".format(max_pool_2.shape)) # [5, 128, 56, 56]\n",
    "\n",
    "        conv_out_3 = F.relu(self.downsample3(max_pool_2))\n",
    "        print(\"Conv. 3 output shape : {}\".format(conv_out_3.shape))\n",
    "\n",
    "        max_pool_3 = F.max_pool2d(conv_out_3, 2)\n",
    "        print(\"Max pool 3 output shape : {}\".format(max_pool_3.shape)) # [5, 256, 28, 28]\n",
    "\n",
    "        conv_out_4 = F.relu(self.downsample4(max_pool_3))\n",
    "        print(\"Conv. 4 output shape : {}\".format(conv_out_4.shape))\n",
    "\n",
    "        max_pool_4 = F.max_pool2d(conv_out_4, 2)\n",
    "        print(\"Max pool 4 output shape : {}\".format(max_pool_4.shape)) # [5, 512, 14, 14]\n",
    "\n",
    "        conv_out_5 = F.relu(self.downsample5(max_pool_4))\n",
    "        print(\"Conv 5 output shape : {}\".format(conv_out_5.shape)) # [5, 1024, 14, 14]\n",
    "        print(\"*****End of down pass*****\")\n",
    "        \n",
    "        d_conv_out_1 = F.relu(self.deconv_w1(conv_out_5, output_size=conv_out_4.size()))\n",
    "        print(\"deconv output 1 shape : {}\".format(d_conv_out_1.shape))\n",
    "        \n",
    "        concat1 = torch.cat([conv_out_4, d_conv_out_1], dim=1)\n",
    "        print(\"cancatenate output 1 shape : {}\".format(concat1.shape))\n",
    "        \n",
    "        rout1 = F.relu(self.rconv_w1(concat1)) \n",
    "        print(\"rout1 shape {}\".format(rout1.shape))\n",
    "        \n",
    "        d_conv_out_2 = F.relu(self.deconv_w2(rout1,output_size=conv_out_3.size() ))\n",
    "        print(\"deconv output 2 shape : {}\".format(d_conv_out_2.shape))\n",
    "        \n",
    "        concat2 = torch.cat([conv_out_3, d_conv_out_2], dim=1)\n",
    "        print(\"cancatenate output 2 shape : {}\".format(concat2.shape))\n",
    "        \n",
    "        rout2 = F.relu(self.rconv_w2(concat2)) \n",
    "        print(\"rout2 shape {}\".format(rout2.shape))\n",
    "        \n",
    "        d_conv_out_3 = F.relu(self.deconv_w3(rout2,output_size=conv_out_2.size() ))\n",
    "        print(\"deconv output 3 shape : {}\".format(d_conv_out_3.shape))\n",
    "        \n",
    "        concat3 = torch.cat([conv_out_2, d_conv_out_3], dim=1)\n",
    "        print(\"cancatenate output 3 shape : {}\".format(concat3.shape))\n",
    "        \n",
    "        rout3 = F.relu(self.rconv_w3(concat3)) \n",
    "        print(\"rout3 shape {}\".format(rout3.shape))\n",
    "\n",
    "        d_conv_out_4 = F.relu(self.deconv_w4(rout3,output_size=conv_out_1.size() ))\n",
    "        print(\"deconv output 4 shape : {}\".format(d_conv_out_4.shape))\n",
    "        \n",
    "        concat4 = torch.cat([conv_out_1, d_conv_out_4], dim=1)\n",
    "        print(\"cancatenate output 4 shape : {}\".format(concat4.shape))\n",
    "        \n",
    "        rout4 = F.relu(self.rconv_w4(concat4)) \n",
    "        print(\"rout4 shape {}\".format(rout4.shape))        \n",
    "        \n",
    "        out = F.relu(self.conv_last(rout4))\n",
    "        print(\"output shape : {}\".format(out.shape))        \n",
    "\n",
    "#         out  is of shape (N, 6, 224, 224 ) How do i take one class from it as it's pixel wise distribution\n",
    "\n",
    "\n",
    "#         scores = torch.zeros((5, 6)) #dummy output \n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : torch.Size([5, 3, 224, 224]), Conv. 1 output shape : torch.Size([5, 64, 224, 224]) \n",
      "Max. pool 1 output shape : torch.Size([5, 64, 112, 112])\n",
      "Conv. 2 output shape : torch.Size([5, 128, 112, 112])\n",
      "Max pool 2 output shape : torch.Size([5, 128, 56, 56])\n",
      "Conv. 3 output shape : torch.Size([5, 256, 56, 56])\n",
      "Max pool 3 output shape : torch.Size([5, 256, 28, 28])\n",
      "Conv. 4 output shape : torch.Size([5, 512, 28, 28])\n",
      "Max pool 4 output shape : torch.Size([5, 512, 14, 14])\n",
      "Conv 5 output shape : torch.Size([5, 1024, 14, 14])\n",
      "*****End of down pass*****\n",
      "deconv output 1 shape : torch.Size([5, 512, 28, 28])\n",
      "cancatenate output 1 shape : torch.Size([5, 1024, 28, 28])\n",
      "rout1 shape torch.Size([5, 512, 28, 28])\n",
      "deconv output 2 shape : torch.Size([5, 256, 56, 56])\n",
      "cancatenate output 2 shape : torch.Size([5, 512, 56, 56])\n",
      "rout2 shape torch.Size([5, 256, 56, 56])\n",
      "deconv output 3 shape : torch.Size([5, 128, 112, 112])\n",
      "cancatenate output 3 shape : torch.Size([5, 256, 112, 112])\n",
      "rout3 shape torch.Size([5, 128, 112, 112])\n",
      "deconv output 4 shape : torch.Size([5, 64, 224, 224])\n",
      "cancatenate output 4 shape : torch.Size([5, 128, 224, 224])\n",
      "rout4 shape torch.Size([5, 64, 224, 224])\n",
      "output shape : torch.Size([5, 6, 224, 224])\n",
      "torch.Size([5, 6, 224, 224])\n",
      "torch.Size([5, 6, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((5, 3, 224, 224), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "model = ResUNet_trial(in_channel=3,num_classes=6)\n",
    "scores = model(x)\n",
    "print(scores.size())  # you should see [5,6,224,224]\n",
    "scores_softmax = F.softmax(scores, 1)\n",
    "print(scores_softmax.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ResUNet():\n",
    "    x = torch.zeros((5, 3, 224, 224), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "    model = ResUNet_trial(in_channel=3,num_classes=6)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "    \n",
    "test_ResUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_softmax = F.softmax(scores, 1)\n",
    "# print(scores_softmax.size())\n",
    "\n",
    "# scores_softmax2 = F.softmax(scores.reshape(scores.size(0), scores.size(1), -1), 2).view_as(scores) \n",
    "# print(scores_softmax2.size())\n",
    "\n",
    "# target = F.softmax(scores, dim=1) > 0.5\n",
    "# labels = torch.argmax(target, dim=1)\n",
    "target = torch.argmax(scores, dim=1)\n",
    "\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool4_out = torch.randn(5, 1024, 14, 14)\n",
    "\n",
    "# downsample = nn.Conv2d(512, 1024, 3, stride=1, padding=1)\n",
    "# h = downsample(max_pool4_out)\n",
    "# print(h.size())\n",
    "\n",
    "upsample = nn.ConvTranspose2d(1024, 512, 3, stride=1, padding=1)\n",
    "\n",
    "output = upsample(max_pool4_out, output_size=max_pool4_out.size())\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def test_UNet():\n",
    "    x = torch.zeros((5, 3, 224, 224), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "    model = UNet(in_channels=3)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "    \n",
    "test_UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs231n]",
   "language": "python",
   "name": "conda-env-cs231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
