{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# assert '.'.join(torch.__version__.split('.')[:2]) == '1.4'\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUNet_trial(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.downsample1 = nn.Conv2d(3, 64, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample2 = nn.Conv2d(64, 128, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample3 = nn.Conv2d(128, 256, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample4 = nn.Conv2d(256, 512, 3, stride=1, padding=1,bias=True)\n",
    "        self.downsample5 = nn.Conv2d(512, 1024, 3, stride=1, padding=1,bias=True)\n",
    "        \n",
    "        self.int_conv_w1 = nn.Conv2d(1024,512,3,padding=1,bias=True)\n",
    "        self.int_conv_w1 = nn.Conv2d(512,256,3,padding=1,bias=True)\n",
    "        self.int_conv_w1 = nn.Conv2d(256,128,3,padding=1,bias=True)\n",
    "        self.int_conv_w1 = nn.Conv2d(128,64,3,padding=1,bias=True)\n",
    "\n",
    "        self.upsample1 = nn.ConvTranspose2d(1024, 512, 3, stride=1, padding=1, bias=True)\n",
    "        self.upsample2 = nn.ConvTranspose2d(512, 256, 3, stride=1, padding=1, bias=True)\n",
    "        self.upsample3 = nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1, bias=True)        \n",
    "        self.upsample4 = nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1, bias=True)\n",
    "        \n",
    "        self.conv_w1 = nn.Conv2d(in_channels=in_channel,out_channels=64,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w1.weight)\n",
    "        \n",
    "        self.conv_w2 = nn.Conv2d(in_channels=64 ,out_channels=128,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w2.weight)\n",
    "\n",
    "        self.conv_w3 = nn.Conv2d(in_channels=128 ,out_channels=256,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w3.weight)\n",
    "\n",
    "        self.conv_w4 = nn.Conv2d(in_channels=256 ,out_channels=512,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w4.weight)\n",
    "\n",
    "        self.conv_w5 = nn.Conv2d(in_channels=512 ,out_channels=1024,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w5.weight)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.deconv_w1 = nn.ConvTranspose2d(1024,512,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w1.weight)\n",
    "        \n",
    "        self.rconv_w1 = nn.Conv2d(1024 ,512,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w1.weight)\n",
    "        \n",
    "        self.deconv_w2 = nn.ConvTranspose2d(512,256,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w2.weight)\n",
    "\n",
    "        self.rconv_w2 = nn.Conv2d(512 ,256,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w2.weight)\n",
    "        \n",
    "        self.deconv_w3 = nn.ConvTranspose2d(256,128,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w3.weight)\n",
    "        \n",
    "        self.rconv_w3 = nn.Conv2d(256 ,128,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w3.weight)\n",
    "        \n",
    "        self.deconv_w4 = nn.ConvTranspose2d(128,64,kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.deconv_w4.weight)\n",
    "        \n",
    "        self.rconv_w4 = nn.Conv2d(128 , 64,kernel_size=3,padding=1,bias=True)\n",
    "        nn.init.kaiming_normal_(self.rconv_w4.weight)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, num_classes, 1)\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****       \n",
    "        \n",
    "        \n",
    "        conv_out_1 = F.relu(self.downsample1(x))\n",
    "        print(\"Input shape : {}, Conv. 1 output shape : {} \".format(x.shape,conv_out_1.shape))\n",
    "\n",
    "        max_pool_1 = F.max_pool2d(conv_out_1, 2)\n",
    "        print(\"Max. pool 1 output shape : {}\".format(max_pool_1.shape)) # [5, 64, 112, 112]\n",
    "\n",
    "        conv_out_2 = F.relu(self.downsample2(max_pool_1))\n",
    "        print(\"Conv. 2 output shape : {}\".format(conv_out_2.shape))\n",
    "\n",
    "        max_pool_2 = F.max_pool2d(conv_out_2, 2)\n",
    "        print(\"Max pool 2 output shape : {}\".format(max_pool_2.shape)) # [5, 128, 56, 56]\n",
    "\n",
    "        conv_out_3 = F.relu(self.downsample3(max_pool_2))\n",
    "        print(\"Conv. 3 output shape : {}\".format(conv_out_3.shape))\n",
    "\n",
    "        max_pool_3 = F.max_pool2d(conv_out_3, 2)\n",
    "        print(\"Max pool 3 output shape : {}\".format(max_pool_3.shape)) # [5, 256, 28, 28]\n",
    "\n",
    "        conv_out_4 = F.relu(self.downsample4(max_pool_3))\n",
    "        print(\"Conv. 4 output shape : {}\".format(conv_out_4.shape))\n",
    "\n",
    "        max_pool_4 = F.max_pool2d(conv_out_4, 2)\n",
    "        print(\"Max pool 4 output shape : {}\".format(max_pool_4.shape)) # [5, 512, 14, 14]\n",
    "\n",
    "        conv_out_5 = F.relu(self.downsample5(max_pool_4))\n",
    "        print(\"Conv 5 output shape : {}\".format(conv_out_5.shape)) # [5, 1024, 14, 14]\n",
    "        print(\"*****End of down pass*****\")\n",
    "        \n",
    "        d_conv_out_1 = F.relu(self.deconv_w1(conv_out_5, output_size=conv_out_4.size()))\n",
    "        print(\"deconv output 1 shape : {}\".format(d_conv_out_1.shape))\n",
    "        \n",
    "        concat1 = torch.cat([conv_out_4, d_conv_out_1], dim=1)\n",
    "        print(\"cancatenate output 1 shape : {}\".format(concat1.shape))\n",
    "        \n",
    "        rout1 = F.relu(self.rconv_w1(concat1)) \n",
    "        print(\"rout1 shape {}\".format(rout1.shape))\n",
    "        \n",
    "        d_conv_out_2 = F.relu(self.deconv_w2(rout1,output_size=conv_out_3.size() ))\n",
    "        print(\"deconv output 2 shape : {}\".format(d_conv_out_2.shape))\n",
    "        \n",
    "        concat2 = torch.cat([conv_out_3, d_conv_out_2], dim=1)\n",
    "        print(\"cancatenate output 2 shape : {}\".format(concat2.shape))\n",
    "        \n",
    "        rout2 = F.relu(self.rconv_w2(concat2)) \n",
    "        print(\"rout2 shape {}\".format(rout2.shape))\n",
    "        \n",
    "        d_conv_out_3 = F.relu(self.deconv_w3(rout2,output_size=conv_out_2.size() ))\n",
    "        print(\"deconv output 3 shape : {}\".format(d_conv_out_3.shape))\n",
    "        \n",
    "        concat3 = torch.cat([conv_out_2, d_conv_out_3], dim=1)\n",
    "        print(\"cancatenate output 3 shape : {}\".format(concat3.shape))\n",
    "        \n",
    "        rout3 = F.relu(self.rconv_w3(concat3)) \n",
    "        print(\"rout3 shape {}\".format(rout3.shape))\n",
    "\n",
    "        d_conv_out_4 = F.relu(self.deconv_w4(rout3,output_size=conv_out_1.size() ))\n",
    "        print(\"deconv output 4 shape : {}\".format(d_conv_out_4.shape))\n",
    "        \n",
    "        concat4 = torch.cat([conv_out_1, d_conv_out_4], dim=1)\n",
    "        print(\"cancatenate output 4 shape : {}\".format(concat4.shape))\n",
    "        \n",
    "        rout4 = F.relu(self.rconv_w4(concat4)) \n",
    "        print(\"rout4 shape {}\".format(rout4.shape))        \n",
    "        \n",
    "        out = F.relu(self.conv_last(rout4))\n",
    "        print(\"output shape : {}\".format(out.shape))        \n",
    "\n",
    "#         out  is of shape (N, 6, 224, 224 ) How do i take one class from it as it's pixel wise distribution\n",
    "\n",
    "\n",
    "#         scores = torch.zeros((5, 6)) #dummy output \n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : torch.Size([5, 3, 224, 224]), Conv. 1 output shape : torch.Size([5, 64, 224, 224]) \n",
      "Max. pool 1 output shape : torch.Size([5, 64, 112, 112])\n",
      "Conv. 2 output shape : torch.Size([5, 128, 112, 112])\n",
      "Max pool 2 output shape : torch.Size([5, 128, 56, 56])\n",
      "Conv. 3 output shape : torch.Size([5, 256, 56, 56])\n",
      "Max pool 3 output shape : torch.Size([5, 256, 28, 28])\n",
      "Conv. 4 output shape : torch.Size([5, 512, 28, 28])\n",
      "Max pool 4 output shape : torch.Size([5, 512, 14, 14])\n",
      "Conv 5 output shape : torch.Size([5, 1024, 14, 14])\n",
      "*****End of down pass*****\n",
      "deconv output 1 shape : torch.Size([5, 512, 28, 28])\n",
      "cancatenate output 1 shape : torch.Size([5, 1024, 28, 28])\n",
      "rout1 shape torch.Size([5, 512, 28, 28])\n",
      "deconv output 2 shape : torch.Size([5, 256, 56, 56])\n",
      "cancatenate output 2 shape : torch.Size([5, 512, 56, 56])\n",
      "rout2 shape torch.Size([5, 256, 56, 56])\n",
      "deconv output 3 shape : torch.Size([5, 128, 112, 112])\n",
      "cancatenate output 3 shape : torch.Size([5, 256, 112, 112])\n",
      "rout3 shape torch.Size([5, 128, 112, 112])\n",
      "deconv output 4 shape : torch.Size([5, 64, 224, 224])\n",
      "cancatenate output 4 shape : torch.Size([5, 128, 224, 224])\n",
      "rout4 shape torch.Size([5, 64, 224, 224])\n",
      "output shape : torch.Size([5, 6, 224, 224])\n",
      "torch.Size([5, 6, 224, 224])\n",
      "torch.Size([5, 6, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((5, 3, 224, 224), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "model = ResUNet_trial(in_channel=3,num_classes=6)\n",
    "scores = model(x)\n",
    "print(scores.size())  # you should see [5,6,224,224]\n",
    "scores_softmax = F.softmax(scores, 1)\n",
    "print(scores_softmax.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ResUNet():\n",
    "    x = torch.zeros((5, 3, 224, 224), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "    model = ResUNet_trial(in_channel=3,num_classes=6)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "    \n",
    "test_ResUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_softmax = F.softmax(scores, 1)\n",
    "# print(scores_softmax.size())\n",
    "\n",
    "# scores_softmax2 = F.softmax(scores.reshape(scores.size(0), scores.size(1), -1), 2).view_as(scores) \n",
    "# print(scores_softmax2.size())\n",
    "\n",
    "# target = F.softmax(scores, dim=1) > 0.5\n",
    "# labels = torch.argmax(target, dim=1)\n",
    "target = torch.argmax(scores, dim=1)\n",
    "\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool4_out = torch.randn(5, 1024, 14, 14)\n",
    "\n",
    "# downsample = nn.Conv2d(512, 1024, 3, stride=1, padding=1)\n",
    "# h = downsample(max_pool4_out)\n",
    "# print(h.size())\n",
    "\n",
    "upsample = nn.ConvTranspose2d(1024, 512, 3, stride=1, padding=1)\n",
    "\n",
    "output = upsample(max_pool4_out, output_size=max_pool4_out.size())\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        # MY experiment\n",
    "        self.fc = nn.Linear(301056, 6)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        # MY experiment\n",
    "        x = out.view(out.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        # x = scores \n",
    "        # _, predicted = torch.max(x.data, 0)\n",
    "\n",
    "\n",
    "        # x = F.adaptive_avg_pool2d(out, output_size=1)\n",
    "        # print(x.size(),x)\n",
    "\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ef19058ede5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# you should see [64, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtest_ResNetUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-ef19058ede5f>\u001b[0m in \u001b[0;36mtest_ResNetUNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_ResNetUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# minibatch size 64, image size [3, 32, 32]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNetUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-679b3793fef0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_class)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "def test_ResNetUNet():\n",
    "    x = torch.zeros((5, 3, 224, 224), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "    model = ResNetUNet(6)\n",
    "    scores = model(x)\n",
    "\n",
    "    # m = nn.Softmax2d()\n",
    "    # outputs = m(scores)\n",
    "    _, predicted = torch.max(scores.data, 1)\n",
    "    print(predicted.size())\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "    \n",
    "test_ResNetUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs231n]",
   "language": "python",
   "name": "conda-env-cs231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
